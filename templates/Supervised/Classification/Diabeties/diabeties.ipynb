{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('diabetes.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Glucose',\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"BMI\"]] = data[['Glucose',\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"BMI\"]].replace(0,np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(data['SkinThickness'].median() , inplace=True)\n",
    "data.fillna(data['Glucose'].mean() , inplace=True)\n",
    "data.fillna(data['Insulin'].mean() , inplace=True)\n",
    "data.fillna(data['BMI'].mean() , inplace=True)\n",
    "data.fillna(data['BloodPressure'].mean() , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop('Outcome',axis = 1)\n",
    "y = data['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.set_index('Pregnancies').to_csv('scale.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x)\n",
    "X = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train  (614, 8)\n",
      "X_test  (154, 8)\n",
      "y_train  (614,)\n",
      "y_test  (154,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# let us now split the dataset into train & test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=10)\n",
    "\n",
    "# print the shape of 'x_train'\n",
    "print(\"X_train \",X_train.shape)\n",
    "\n",
    "# print the shape of 'x_test'\n",
    "print(\"X_test \",X_test.shape)\n",
    "\n",
    "# print the shape of 'y_train'\n",
    "print(\"y_train \",y_train.shape)\n",
    "\n",
    "# print the shape of 'y_test'\n",
    "print(\"y_test \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(random_state=10))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Bagging Classifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "# build the model\n",
    "meta_estimator = BaggingClassifier(tree.DecisionTreeClassifier(random_state=10))\n",
    "\n",
    "# fit the model\n",
    "meta_estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the values\n",
    "y_pred = meta_estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Precision Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging Meta-estimator</td>\n",
       "      <td>0.702765</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.74026</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  AUC Score  Precision Score  Recall Score  \\\n",
       "0  Bagging Meta-estimator   0.702765         0.711111      0.542373   \n",
       "\n",
       "   Accuracy Score  f1-score  \n",
       "0         0.74026  0.615385  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# create a list of column names\n",
    "cols = ['Model', 'AUC Score', 'Precision Score', 'Recall Score','Accuracy Score','f1-score']\n",
    "\n",
    "# creating an empty dataframe of the colums\n",
    "result_tabulation = pd.DataFrame(columns = cols)\n",
    "\n",
    "# compiling the required information\n",
    "Bagging_Meta_estimator = pd.Series({'Model': \"Bagging Meta-estimator\",\n",
    "                     'AUC Score' : metrics.roc_auc_score(y_test, y_pred),\n",
    "                 'Precision Score': metrics.precision_score(y_test, y_pred),\n",
    "                 'Recall Score': metrics.recall_score(y_test, y_pred),\n",
    "                 'Accuracy Score': metrics.accuracy_score(y_test, y_pred),\n",
    "                  'f1-score':metrics.f1_score(y_test, y_pred)})\n",
    "\n",
    "\n",
    "\n",
    "# appending our result table\n",
    "result_tabulation = result_tabulation.append(Bagging_Meta_estimator , ignore_index = True)\n",
    "\n",
    "# view the result table\n",
    "result_tabulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(random_state=10)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# build the model\n",
    "adaboost = AdaBoostClassifier(random_state=10)\n",
    "# fit the model\n",
    "adaboost.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the values\n",
    "y_pred_adaboost  = adaboost.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Precision Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging Meta-estimator</td>\n",
       "      <td>0.702765</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.722926</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.593220</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.648148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  AUC Score  Precision Score  Recall Score  \\\n",
       "0  Bagging Meta-estimator   0.702765         0.711111      0.542373   \n",
       "1                AdaBoost   0.722926         0.714286      0.593220   \n",
       "\n",
       "   Accuracy Score  f1-score  \n",
       "0        0.740260  0.615385  \n",
       "1        0.753247  0.648148  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_metrics = pd.Series({'Model': \"AdaBoost\",\n",
    "                     'AUC Score' : metrics.roc_auc_score(y_test, y_pred_adaboost),\n",
    "                 'Precision Score': metrics.precision_score(y_test, y_pred_adaboost),\n",
    "                 'Recall Score': metrics.recall_score(y_test, y_pred_adaboost),\n",
    "                 'Accuracy Score': metrics.accuracy_score(y_test, y_pred_adaboost),\n",
    "                  'f1-score':metrics.f1_score(y_test, y_pred_adaboost)})\n",
    "\n",
    "\n",
    "\n",
    "# appending our result table\n",
    "result_tabulation = result_tabulation.append(adaboost_metrics , ignore_index = True)\n",
    "\n",
    "# view the result table\n",
    "result_tabulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.01, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Xgboost\n",
    "#import xgboost classifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# build the model\n",
    "xgbm = XGBClassifier(random_state=1,learning_rate=0.01)\n",
    "# fit the model\n",
    "xgbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the values\n",
    "y_pred_xgbm  = xgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Precision Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging Meta-estimator</td>\n",
       "      <td>0.702765</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.722926</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.593220</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.648148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBM</td>\n",
       "      <td>0.677342</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.491525</td>\n",
       "      <td>0.720779</td>\n",
       "      <td>0.574257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  AUC Score  Precision Score  Recall Score  \\\n",
       "0  Bagging Meta-estimator   0.702765         0.711111      0.542373   \n",
       "1                AdaBoost   0.722926         0.714286      0.593220   \n",
       "2                    XGBM   0.677342         0.690476      0.491525   \n",
       "\n",
       "   Accuracy Score  f1-score  \n",
       "0        0.740260  0.615385  \n",
       "1        0.753247  0.648148  \n",
       "2        0.720779  0.574257  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compiling the required information\n",
    "xgbm_metrices = pd.Series({'Model': \"XGBM\",\n",
    "                     'AUC Score' : metrics.roc_auc_score(y_test, y_pred_xgbm),\n",
    "                 'Precision Score': metrics.precision_score(y_test, y_pred_xgbm),\n",
    "                 'Recall Score': metrics.recall_score(y_test, y_pred_xgbm),\n",
    "                 'Accuracy Score': metrics.accuracy_score(y_test, y_pred_xgbm),\n",
    "\n",
    "                  'f1-score':metrics.f1_score(y_test, y_pred_xgbm)})\n",
    "\n",
    "\n",
    "\n",
    "# appending our result table\n",
    "result_tabulation = result_tabulation.append(xgbm_metrices , ignore_index = True)\n",
    "\n",
    "# view the result table\n",
    "result_tabulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOgistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create logistic regression\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "logistic.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the values\n",
    "y_pred = logistic.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Precision Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging Meta-estimator</td>\n",
       "      <td>0.702765</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.722926</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.593220</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.648148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBM</td>\n",
       "      <td>0.677342</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.491525</td>\n",
       "      <td>0.720779</td>\n",
       "      <td>0.574257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.691971</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>0.746753</td>\n",
       "      <td>0.580645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  AUC Score  Precision Score  Recall Score  \\\n",
       "0  Bagging Meta-estimator   0.702765         0.711111      0.542373   \n",
       "1                AdaBoost   0.722926         0.714286      0.593220   \n",
       "2                    XGBM   0.677342         0.690476      0.491525   \n",
       "3     Logistic Regression   0.691971         0.794118      0.457627   \n",
       "\n",
       "   Accuracy Score  f1-score  \n",
       "0        0.740260  0.615385  \n",
       "1        0.753247  0.648148  \n",
       "2        0.720779  0.574257  \n",
       "3        0.746753  0.580645  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compiling the required information\n",
    "logisitc = pd.Series({'Model': \"Logistic Regression\",\n",
    "                     'AUC Score' : metrics.roc_auc_score(y_test, y_pred),\n",
    "                 'Precision Score': metrics.precision_score(y_test, y_pred),\n",
    "                 'Recall Score': metrics.recall_score(y_test, y_pred),\n",
    "                 'Accuracy Score': metrics.accuracy_score(y_test, y_pred),\n",
    "                  'f1-score':metrics.f1_score(y_test, y_pred)})\n",
    "\n",
    "\n",
    "\n",
    "# appending our result table\n",
    "result_tabulation = result_tabulation.append(logisitc , ignore_index = True)\n",
    "\n",
    "# view the result table\n",
    "result_tabulation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# build the model\n",
    "GNB = GaussianNB()\n",
    "\n",
    "# fit the model\n",
    "GNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the values\n",
    "y_pred_GNB  = GNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Precision Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging Meta-estimator</td>\n",
       "      <td>0.702765</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.722926</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.593220</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.648148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBM</td>\n",
       "      <td>0.677342</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.491525</td>\n",
       "      <td>0.720779</td>\n",
       "      <td>0.574257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.691971</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>0.746753</td>\n",
       "      <td>0.580645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.692239</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.603774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  AUC Score  Precision Score  Recall Score  \\\n",
       "0  Bagging Meta-estimator   0.702765         0.711111      0.542373   \n",
       "1                AdaBoost   0.722926         0.714286      0.593220   \n",
       "2                    XGBM   0.677342         0.690476      0.491525   \n",
       "3     Logistic Regression   0.691971         0.794118      0.457627   \n",
       "4             Naive Bayes   0.692239         0.680851      0.542373   \n",
       "\n",
       "   Accuracy Score  f1-score  \n",
       "0        0.740260  0.615385  \n",
       "1        0.753247  0.648148  \n",
       "2        0.720779  0.574257  \n",
       "3        0.746753  0.580645  \n",
       "4        0.727273  0.603774  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compiling the required information\n",
    "GNB_metrices = pd.Series({'Model': \"Naive Bayes\",\n",
    "                     'AUC Score' : metrics.roc_auc_score(y_test, y_pred_GNB),\n",
    "                 'Precision Score': metrics.precision_score(y_test, y_pred_GNB),\n",
    "                 'Recall Score': metrics.recall_score(y_test, y_pred_GNB),\n",
    "                 'Accuracy Score': metrics.accuracy_score(y_test, y_pred_GNB),\n",
    "\n",
    "                  'f1-score':metrics.f1_score(y_test, y_pred_GNB)})\n",
    "\n",
    "\n",
    "\n",
    "# appending our result table\n",
    "result_tabulation = result_tabulation.append(GNB_metrices , ignore_index = True)\n",
    "\n",
    "# view the result table\n",
    "result_tabulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#create new a knn model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit model to data\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the values\n",
    "y_pred_knn  = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Precision Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging Meta-estimator</td>\n",
       "      <td>0.702765</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.722926</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.593220</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.648148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBM</td>\n",
       "      <td>0.677342</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.491525</td>\n",
       "      <td>0.720779</td>\n",
       "      <td>0.574257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.691971</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>0.746753</td>\n",
       "      <td>0.580645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.692239</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.603774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.655129</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>0.540000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  AUC Score  Precision Score  Recall Score  \\\n",
       "0  Bagging Meta-estimator   0.702765         0.711111      0.542373   \n",
       "1                AdaBoost   0.722926         0.714286      0.593220   \n",
       "2                    XGBM   0.677342         0.690476      0.491525   \n",
       "3     Logistic Regression   0.691971         0.794118      0.457627   \n",
       "4             Naive Bayes   0.692239         0.680851      0.542373   \n",
       "5                     KNN   0.655129         0.658537      0.457627   \n",
       "\n",
       "   Accuracy Score  f1-score  \n",
       "0        0.740260  0.615385  \n",
       "1        0.753247  0.648148  \n",
       "2        0.720779  0.574257  \n",
       "3        0.746753  0.580645  \n",
       "4        0.727273  0.603774  \n",
       "5        0.701299  0.540000  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compiling the required information\n",
    "knn_metrics = pd.Series({'Model': \"KNN\",\n",
    "                     'AUC Score' : metrics.roc_auc_score(y_test, y_pred_knn),\n",
    "                 'Precision Score': metrics.precision_score(y_test, y_pred_knn),\n",
    "                 'Recall Score': metrics.recall_score(y_test, y_pred_knn),\n",
    "                 'Accuracy Score': metrics.accuracy_score(y_test, y_pred_knn),\n",
    "                  'f1-score':metrics.f1_score(y_test, y_pred_knn)})\n",
    "\n",
    "\n",
    "\n",
    "# appending our result table\n",
    "result_tabulation = result_tabulation.append(knn_metrics , ignore_index = True)\n",
    "\n",
    "# view the result table\n",
    "result_tabulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_random = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in y_random:\n",
    "    if i >= 0.5 :\n",
    "        a.append(1)\n",
    "    else :\n",
    "        a.append(0)\n",
    "y_random = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Precision Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging Meta-estimator</td>\n",
       "      <td>0.702765</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.722926</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.593220</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.648148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBM</td>\n",
       "      <td>0.677342</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.491525</td>\n",
       "      <td>0.720779</td>\n",
       "      <td>0.574257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.691971</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>0.746753</td>\n",
       "      <td>0.580645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.692239</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.603774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.655129</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>0.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.721766</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.559322</td>\n",
       "      <td>0.759740</td>\n",
       "      <td>0.640777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  AUC Score  Precision Score  Recall Score  \\\n",
       "0  Bagging Meta-estimator   0.702765         0.711111      0.542373   \n",
       "1                AdaBoost   0.722926         0.714286      0.593220   \n",
       "2                    XGBM   0.677342         0.690476      0.491525   \n",
       "3     Logistic Regression   0.691971         0.794118      0.457627   \n",
       "4             Naive Bayes   0.692239         0.680851      0.542373   \n",
       "5                     KNN   0.655129         0.658537      0.457627   \n",
       "6           Random Forest   0.721766         0.750000      0.559322   \n",
       "\n",
       "   Accuracy Score  f1-score  \n",
       "0        0.740260  0.615385  \n",
       "1        0.753247  0.648148  \n",
       "2        0.720779  0.574257  \n",
       "3        0.746753  0.580645  \n",
       "4        0.727273  0.603774  \n",
       "5        0.701299  0.540000  \n",
       "6        0.759740  0.640777  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compiling the required information\n",
    "random_metrics = pd.Series({'Model': \"Random Forest\",\n",
    "                     'AUC Score' : metrics.roc_auc_score(y_test, y_random),\n",
    "                 'Precision Score': metrics.precision_score(y_test, y_random),\n",
    "                 'Recall Score': metrics.recall_score(y_test, y_random),\n",
    "                 'Accuracy Score': metrics.accuracy_score(y_test, y_random),\n",
    "                  'f1-score':metrics.f1_score(y_test, y_random)})\n",
    "\n",
    "\n",
    "\n",
    "# appending our result table\n",
    "result_tabulation = result_tabulation.append(random_metrics , ignore_index = True)\n",
    "\n",
    "# view the result table\n",
    "result_tabulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Bagging Meta Estimator\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rf, open('diabeties.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
